##### Create scaffolding
#####

# Create resource group
#
resource "azurerm_resource_group" "rgwork" {

  name     = "rgaif${var.location_code}${var.random_string}"
  location = var.location

  tags = var.tags
}

# Create a Log Analytics Workspace that all resources specific to this workload will
# write configured resource logs and metrics to
#
resource "azurerm_log_analytics_workspace" "log_analytics_workspace" {
  name                = "law${var.purpose}${var.location_code}${var.random_string}"
  location            = var.location
  resource_group_name = azurerm_resource_group.rgwork.name

  sku               = "PerGB2018"
  retention_in_days = 30

  tags = var.tags

  lifecycle {
    ignore_changes = [
      tags["created_date"],
      tags["created_by"]
    ]
  }
}

# Configure diagnostic settings for Log Analytics Workspace
#
resource "azurerm_monitor_diagnostic_setting" "diag_base" {
  depends_on = [azurerm_log_analytics_workspace.log_analytics_workspace]

  name                       = "diag-base"
  target_resource_id         = azurerm_log_analytics_workspace.log_analytics_workspace.id
  log_analytics_workspace_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  enabled_log {
    category = "Audit"
  }
  enabled_log {
    category = "SummaryLogs"
  }
}

#####  Create resources required by AI Foundry Hub
#####

# Create Application Insights instance. This will be used by the Azure Foundry instance to capture logs and metrics generated by the compute used within the hub
# or project.
resource "azurerm_application_insights" "aifoundry_appins" {
  depends_on = [
    azurerm_log_analytics_workspace.log_analytics_workspace
  ]
  name                = "${local.app_insights_prefix}${var.purpose}${var.location_code}${var.random_string}"
  location            = var.location
  resource_group_name = azurerm_resource_group.rgwork.name
  workspace_id        = azurerm_log_analytics_workspace.log_analytics_workspace.id
  application_type    = "other"
}

# Create storage account which will be used as the default storage account for the AI Foundry instance. The storage account will block public access 
# and use resource access rules to allow the AI Foundry Hub and projects. Key-based authentication will be disabled to enforce Entra ID authentication 
# and Azure RBAC authorization. Key-based authentication will be disabled to enforce Entra ID authentication and Azure RBAC authorization.
module "storage_account_ai_foundry" {

  source              = "../../modules/storage-account"
  purpose             = var.purpose
  random_string       = var.random_string
  location            = var.location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  # Resource logs for the storage account will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Disable storage access keys
  key_based_authentication = false

  # Block public access and use resource rules to allow the AI Foundry Hub and projects to access the storage account through the Microsoft public backbone 
  # using a managed identity.
  network_access_default = "Deny"
  resource_access = [
    {
      endpoint_resource_id = "/subscriptions/${var.sub_id}/resourcegroups/*/providers/Microsoft.MachineLearningServices/workspaces/*"
    }
  ]
}

# Create Key Vault which will hold secrets for the AI Foundry instance. Public access will be disabled with the Trusted Services Exception to allow
# the AI Foundry instance to access the Key Vault for retrieval of secrets.
#
module "keyvault_aifoundry" {

  source              = "../../modules/key-vault"
  random_string       = var.random_string
  location            = var.location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  purpose             = var.purpose
  tags                = var.tags

  # Resource logs for the Key Vault will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # The user specified here will have the Azure RBAC Key Vault Administrator role over the Azure Key Vault instance
  kv_admin_object_id = var.user_object_id

  # Disable public access and allow the Trusted Azure Service firewall exception
  firewall_default_action = "Deny"
  firewall_bypass         = "AzureServices"
}

# Create an Azure Container Registry instance. This instance will be created with public access disabled with the Trusted Services Exception to allow
# AI Foundry compute instances access to the Container Registry for pulling container images.
#
module "container_registry" {
  source              = "../../modules/container-registry"
  purpose             = var.purpose
  random_string       = var.random_string
  location            = var.location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  # Resource logs for the Container Registry will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Module has incoming public access disabled by default with trusted Azure Services bypass
  default_network_action = "Deny"
  bypass_network_rules   = "AzureServices"
}

##### Create optional resources for AI Foundry Hub
#####

# Create storage account which will be hold data to be processed by AI foundry. The storage account will block public access 
# and use resource access rules to allow the AI Foundry Hub and projects. Key-based authentication will be disabled to enforce Entra ID authentication 
# and Azure RBAC authorization. Key-based authentication will be disabled to enforce Entra ID authentication and Azure RBAC authorization.
module "storage_account_data" {

  source              = "../../modules/storage-account"
  purpose             = "${var.purpose}data"
  random_string       = var.random_string
  location            = var.location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  # Resource logs for the storage account will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Disable storage access keys
  key_based_authentication = false

  # Block public access and use resource rules to allow the AI Foundry Hub and projects (which are just Machine Learning workspaces under the hood) and AI Search instances 
  # to access the storage account through the Microsoft public backbone using a managed identity. AI Search will need to access this storage account if you are using the
  # Skill Sets to pull data.
  network_access_default = "Deny"
  resource_access = [
    {
      endpoint_resource_id = "/subscriptions/${var.sub_id}/resourcegroups/*/providers/Microsoft.MachineLearningServices/workspaces/*"
    },
    {
      endpoint_resource_id = "/subscriptions/${var.sub_id}/resourcegroups/*/providers/Microsoft.Search/searchServices/*"
    }
  ]
}

# Create a blob container in the data storage account
#
resource "azurerm_storage_container" "blob_data" {
  name                  = local.container_name
  storage_account_id    = module.storage_account_data.id
  container_access_type = "private"
}

# Create an Azure OpenAI Service instance. Public access will be disabled with the Trusted Services Exception to allow
# AI Foundry and AI Search access to the Azure OpenAI Service. AI Search will use the Azure OpenAI Service when ingesting data
# and creating vector embeddings. The module will automatically create deployments for GPT-4o and text-embedding-3-large models.
module "openai_aifoundry" {

  source              = "../../modules/aoai"
  random_string       = var.random_string
  location            = local.openai_region
  location_code       = local.openai_region_code
  resource_group_name = azurerm_resource_group.rgwork.name
  purpose             = var.purpose
  tags                = var.tags

  # Resource logs for the Azure OpenAI Service will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Module has incoming public access disabled by default with trusted Azure Services bypass (this is hardcoded in the downstream module)
  # and outgoing access blocked except for the exception for the AI Search instance.
  public_network_access = false
  allowed_fqdn_list = [
    "ais${var.purpose}${var.location_code}${var.random_string}.search.windows.net"
  ]
}

# Create an Azure OpenAI Service instance. Public access will be disabled with the Trusted Services Exception to allow
# AI Foundry and AI Search access to the Azure OpenAI Service. AI Search will use the Azure OpenAI Service when ingesting data
# and creating vector embeddings. The module will automatically create deployments for GPT-4o and text-embedding-3-large models.
module "ai_services_aifoundry" {

  source              = "../../modules/ai-service"
  random_string       = var.random_string
  location            = local.openai_region
  location_code       = local.openai_region_code
  resource_group_name = azurerm_resource_group.rgwork.name
  resource_group_id   = azurerm_resource_group.rgwork.id
  purpose             = var.purpose
  tags                = var.tags

  # Resource logs for the Azure AI Services will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Module has incoming public access disabled by default with trusted Azure Services bypass (this is hardcoded in the downstream module)
  # and outgoing access blocked except for the exception for the AI Search instance.
  allowed_fqdn_list = [
    "ais${var.purpose}${var.location_code}${var.random_string}.search.windows.net"
  ]
}

# Create an Azure AI Search instance that will be used to store indexes and vector embeddings. The instance will have public network access disabled
# and will use the Trusted Services Exception to allow the AI Foundry, AI Services, and Azure OpenAI Service instances to access it.
#
module "ai_search" {

  depends_on = [
    module.ai_services_aifoundry,
    module.openai_aifoundry,
    module.storage_account_data
  ]

  source              = "../../modules/ai-search"
  purpose             = var.purpose
  random_string       = var.random_string
  resource_group_name = azurerm_resource_group.rgwork.name
  resource_group_id   = azurerm_resource_group.rgwork.id
  location            = var.location
  location_code       = var.location_code
  tags                = var.tags

  # Resource logs for the service will be sent to this Log Analytics Workspace
  law_resource_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  # Using Basic SKU to save in costs which means the Shared Private Access feature will be unavailable. Upstream services accessed by Azure Search will need
  # to allow Trusted Services firewall exception. Trusted Services exception is used here to allow the AI Search instance to be accessed by an AI Service or Azure
  # OpenAI Service instance for the chat with your data feature.
  sku                     = "basic"
  public_network_access   = "disabled"
  trusted_services_bypass = "AzureServices"
}

##### Create AI Foundry Hub and child resources
#####

# Create the AI Foundry Hub. 
# For network controls, the hub will be created with public network access disabled for inbound access and approved outbound only for outbound access
# from compute used within the AI Foundry instance. The Azure Firewall instance created in the managed virtual network will be the Standard SKU to support
# FQDN-based rules. Managed private endpoints for the Azure OpenAI Service, Azure AI Services, Azure AI Search, and the blob and file endpoints of the 
# data storage account will be created.

# For identity controls, the hub will use a system-assigned managed identity which the platform will automatically grant the necessary role assignments. The 
# hub will be created with an identity-based datastore to limit the secrets stored in the Azure Key Vault.
resource "azapi_resource" "foundry_hub" {
  depends_on = [
    module.storage_account_ai_foundry,
    module.storage_account_data,
    module.keyvault_aifoundry,
    module.openai_aifoundry,
    module.ai_services_aifoundry,
    module.ai_search,
    module.container_registry
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces@2024-10-01-preview"
  name                      = "${local.ai_foundry_hub_prefix}${var.purpose}${var.location_code}${var.random_string}"
  parent_id                 = azurerm_resource_group.rgwork.id
  location                  = var.location
  schema_validation_enabled = false

  body = {
    identity = {
      type = "SystemAssigned"
    }

    kind = "Hub"
    sku = {
      tier = "Basic"
      name = "Basic"
    }

    properties = {
      friendlyName = "Sample-Hub"
      description  = "Sample AI Foundry Hub"

      applicationInsights = azurerm_application_insights.aifoundry_appins.id
      keyVault            = module.keyvault_aifoundry.id
      storageAccount      = module.storage_account_ai_foundry.id
      containerRegistry   = module.container_registry.id

      publicNetworkAccess = "disabled"
      managedNetwork = {
        isolationMode = "AllowOnlyApprovedOutbound"
        firewallSku   = "Standard"
        outboundRules = {

          # Create managed private endpoints
          #

          # Create managed private endpoint for the Azure OpenAI instance
          managed_pe_aoai = {
            type = "PrivateEndpoint"
            destination = {
              serviceResourceId = module.openai_aifoundry.id
              subresourceTarget = "account"
            }
          }
          # Create managed private endpoint for the Azure AI Service
          managed_pe_aiservice = {
            type = "PrivateEndpoint"
            destination = {
              serviceResourceId = module.ai_services_aifoundry.id
              subresourceTarget = "account"
            }
          }
          # Create the managed private endpoint for the AI Search instance
          managed_pe_aisearch = {
            type = "PrivateEndpoint"
            destination = {
              serviceResourceId = module.ai_search.id
              subresourceTarget = "SearchService"
            }
          },
          # Create the managed private endpoint for the Azure Storage Account blob and file endpoints of the data storage account
          managed_pe_data_blob = {
            type = "PrivateEndpoint"
            destination = {
              serviceResourceId = module.storage_account_data.id
              subresourceTarget = "blob"
            }
          }
          managed_pe_data_file = {
            type = "PrivateEndpoint"
            destination = {
              serviceResourceId = module.storage_account_data.id
              subresourceTarget = "file"
            }
          }

          # Create required fqdn rules to allow compute build in the managed virtual network to download tools and libraries
          #
          AllowPypi = {
            type        = "FQDN"
            destination = "pypi.org"
            category    = "UserDefined"
          }
          AllowPythonHostedWildcard = {
            type        = "FQDN"
            destination = "*.pythonhosted.org"
            category    = "UserDefined"
          }
          AllowAnacondaCom = {
            type        = "FQDN"
            destination = "anaconda.com"
            category    = "UserDefined"
          }
          AllowAnacondaComWildcard = {
            type        = "FQDN"
            destination = "*.anaconda.com"
            category    = "UserDefined"
          }
          AllowAnacondaOrgWildcard = {
            type        = "FQDN"
            destination = "*.anaconda.org"
            category    = "UserDefined"
          }


          # Create fqdn rules to support usage of SSH to compute instances in a managed virtual network from Visual Studio Code
          #
          AllowVsCodeDevWildcard = {
            type        = "FQDN"
            destination = "*.vscode.dev"
            category    = "UserDefined"
          }
          AllowVsCodeBlob = {
            type        = "FQDN"
            destination = "vscode.blob.core.windows.net"
            category    = "UserDefined"
          }
          AllowGalleryCdnWildcard = {
            type        = "FQDN"
            destination = "*.gallerycdn.vsassets.io"
            category    = "UserDefined"
          }
          AllowRawGithub = {
            type        = "FQDN"
            destination = "raw.githubusercontent.com"
            category    = "UserDefined"
          }
          AllowVsCodeUnpkWildcard = {
            type        = "FQDN"
            destination = "*.vscode-unpkg.net"
            category    = "UserDefined"
          }
          AllowVsCodeCndWildcard = {
            type        = "FQDN"
            destination = "*.vscode-cdn.net"
            category    = "UserDefined"
          }
          AllowVsCodeExperimentsWildcard = {
            type        = "FQDN"
            destination = "*.vscodeexperiments.azureedge.net"
            category    = "UserDefined"
          }
          AllowDefaultExpTas = {
            type        = "FQDN"
            destination = "default.exp-tas.com"
            category    = "UserDefined"
          }
          AllowCodeVisualStudio = {
            type        = "FQDN"
            destination = "code.visualstudio.com"
            category    = "UserDefined"
          }
          AllowUpdateCodeVisualStudio = {
            type        = "FQDN"
            destination = "update.code.visualstudio.com"
            category    = "UserDefined"
          }
          AllowVsMsecndNet = {
            type        = "FQDN"
            destination = "*.vo.msecnd.net"
            category    = "UserDefined"
          }
          AllowMarketplaceVisualStudio = {
            type        = "FQDN"
            destination = "marketplace.visualstudio.com"
            category    = "UserDefined"
          }
          AllowVsCodeDownload = {
            type        = "FQDN"
            destination = "vscode.download.prss.microsoft.com"
            category    = "UserDefined"
          }
        }
      }

      # Allow the platform to grant the SMI for the hub Azure AI Administrator on the resource group
      allowRoleAssignmentOnRg = true

      # Set the authentication for system datastores to use the managed identity of the hub instead of storing the API keys as secrets in Key Vault
      systemDatastoresAuthMode = "identity"

      # Place the workspace in the resource group created at the beginning of this template
      workspaceHubConfig = {
        defaultWorkspaceResourceGroup = azurerm_resource_group.rgwork.id
      }
    }

    # Set the tags for the hub
    tags = var.tags
  }

  # Output the managed identities principal ID for the hub
  response_export_values = [
    "identity.principalId"
  ]

  # Ignore updates to these tags on additional Terraform deployments
  lifecycle {
    ignore_changes = [
      tags["created_date"],
      tags["created_by"]
    ]
  }
}

# Create diagnostic settings to capture resource logs and metrics for AI Foundry Hub and place them in the Log Analytics Workspace
#
resource "azurerm_monitor_diagnostic_setting" "foundry_hub_diag_base" {
  depends_on = [
    azapi_resource.foundry_hub,
    azurerm_log_analytics_workspace.log_analytics_workspace
  ]

  name                       = "diag-base"
  target_resource_id         = azapi_resource.foundry_hub.id
  log_analytics_workspace_id = azurerm_log_analytics_workspace.log_analytics_workspace.id

  enabled_log {
    category = "ComputeInstanceEvent"
  }
}

# Create a workspace connection in the AI Foundry Hub to the Azure OpenAI Service instnance for the AI Foundry Hub and make it shared to all AI Foundry Projects
#
resource "azapi_resource" "hub_openai_connection" {
  depends_on = [
    module.openai_aifoundry,
    azapi_resource.foundry_hub
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces/connections@2024-04-01-preview"
  name                      = "conn${module.openai_aifoundry.name}"
  parent_id                 = azapi_resource.foundry_hub.id
  schema_validation_enabled = true

  body = {
    properties = {
      authType      = "AAD"
      category      = "AzureOpenAI"
      isSharedToAll = true
      target        = module.openai_aifoundry.endpoint
      metadata = {
        ApiType    = "Azure"
        ApiVersion = "2024-10-21"
        Location   = local.openai_region
        ResourceId = module.openai_aifoundry.id
      }
    }
  }
}

# Create a workspace connection in the AI Foundry Hub to the Azure AI Service instance for the OpenAI endpoint for the AI Foundry Hub and make it shared to all AI Foundry Projects
#
resource "azapi_resource" "hub_ai_service_connection" {
  depends_on = [
    module.ai_services_aifoundry,
    azapi_resource.foundry_hub
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces/connections@2024-04-01-preview"
  name                      = "conn${module.ai_services_aifoundry.name}"
  parent_id                 = azapi_resource.foundry_hub.id
  schema_validation_enabled = true

  body = {
    properties = {
      authType      = "AAD"
      category      = "AIServices"
      isSharedToAll = true
      target        = "https://${module.ai_services_aifoundry.custom_subdomain}.openai.azure.com"
      metadata = {
        ApiType    = "Azure"
        ApiVersion = "2024-10-21"
        Location   = local.openai_region
        ResourceId = module.ai_services_aifoundry.id
      }
    }
  }
}

# Create a workspace connection in the AI Foundry Hub to the Azure AI Search instance for the AI Foundry Hub and make it shared to all AI Foundry Projects
#
resource "azapi_resource" "hub_aisearch_connection" {
  depends_on = [
    module.ai_search,
    azapi_resource.foundry_hub
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces/connections@2024-04-01-preview"
  name                      = "conn${module.ai_search.name}"
  parent_id                 = azapi_resource.foundry_hub.id
  schema_validation_enabled = true

  body = {
    properties = {
      authType      = "AAD"
      category      = "CognitiveSearch"
      isSharedToAll = true
      target        = "https://${module.ai_search.name}.search.windows.net"
      metadata = {
        ApiType    = "Azure"
        ApiVersion = "2024-05-01-preview"
        ResourceId = module.ai_search.id
      }
    }
  }
}

# Create an AI Foundry Project under the AI Foundry Hub
#
resource "azapi_resource" "foundry_project" {
  depends_on = [
    azapi_resource.foundry_hub,
    azapi_resource.hub_ai_service_connection,
    azapi_resource.hub_openai_connection,
    azapi_resource.hub_aisearch_connection
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces@2024-10-01-preview"
  name                      = "${local.ai_foundry_project_prefix}${var.purpose}${var.location_code}${var.random_string}"
  parent_id                 = azurerm_resource_group.rgwork.id
  location                  = var.location
  schema_validation_enabled = false

  body = {
    identity = {
      type = "SystemAssigned"
    }

    kind = "Project"
    sku = {
      tier = "Basic"
      name = "Basic"
    }

    properties = {
      friendlyName = "Sample-Project"
      description  = "Sample AI Foundry Project"

      hubResourceId = azapi_resource.foundry_hub.id

      # Do not apply any permissions on the resource group
      allowRoleAssignmentOnRg = false

      # Probably unnecessary due to hub configuration but can't hurt
      systemDatastoresAuthMode = "identity"

      workspaceHubConfig = {
        defaultWorkspaceResourceGroup = azurerm_resource_group.rgwork.id
      }
    }
    tags = var.tags
  }
  # Export system-assigned managed identity principal ID for the project
  response_export_values = [
    "identity.principalId"
  ]
  # Ignore updates to these tags on additional Terraform deployments
  lifecycle {
    ignore_changes = [
      tags["created_date"],
      tags["created_by"]
    ]
  }
}

# Pause for 10 seconds to allow the identities for the hub and project to be replicated through Entra ID
#
resource "time_sleep" "wait_project_identities" {
  depends_on = [
    azapi_resource.foundry_project
  ]
  create_duration = "10s"
}

# Create a workspace datastore to the Azure Storage Account blob endpoint for the AI Foundry Project. This will appear as a connection in the project.
#
resource "azapi_resource" "project_storage_data_datastore" {
  depends_on = [
    azapi_resource.foundry_project,
    module.storage_account_data,
    azurerm_storage_container.blob_data
  ]

  type                      = "Microsoft.MachineLearningServices/workspaces/datastores@2024-10-01"
  name                      = substr("conn${module.storage_account_data.name}", 0, 24)
  parent_id                 = azapi_resource.foundry_project.id
  schema_validation_enabled = true

  body = {
    properties = {
      description   = "Data storage account for AI Foundry Project"
      datastoreType = "AzureBlob"
      accountName   = module.storage_account_data.name
      endpoint      = "core.windows.net"
      protocol      = "https"
      containerName = local.container_name

      # Set the authentication to use the user's Entra ID identity
      credentials = {
        credentialsType = "None"
      }
      serviceDataAccessAuthIdentity = "None"

      tags = var.tags
    }
  }
}

##### Create Private Endpoints for AI Foundry Hub and required resources
#####

# Create a Private Endpoints Azure Foundry Hub instance
module "private_endpoint_foundry_hub" {
  depends_on = [
    time_sleep.wait_project_identities
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = azapi_resource.foundry_hub.name
  resource_id      = azapi_resource.foundry_hub.id
  subresource_name = "amlworkspace"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.api.azureml.ms",

    # Done for completion but don't believe records in this are actually used today
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.notebooks.azure.net"
  ]
}

# Create Private Endpoints for default storage account
#
module "private_endpoint_st_aifoundry_blob" {
  depends_on = [
    module.private_endpoint_foundry_hub
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_ai_foundry.name
  resource_id      = module.storage_account_ai_foundry.id
  subresource_name = "blob"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.blob.core.windows.net"
  ]
}

module "private_endpoint_st_aifoundry_file" {
  depends_on = [
    module.private_endpoint_st_data_blob
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_ai_foundry.name
  resource_id      = module.storage_account_ai_foundry.id
  subresource_name = "file"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.file.core.windows.net"
  ]
}

# Create a Private Endpoints for Key Vault
#
module "private_endpoint_kv" {
  depends_on = [
    module.keyvault_aifoundry
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.keyvault_aifoundry.name
  resource_id      = module.keyvault_aifoundry.id
  subresource_name = "vault"


  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.vaultcore.azure.net"
  ]
}

# Create a Private Endpoint for Container Registry
#
module "private_endpoint_container_registry" {
  depends_on = [
    module.private_endpoint_kv
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.container_registry.name
  resource_id      = module.container_registry.id
  subresource_name = "registry"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.azurecr.io"
  ]
}

##### Create Private Endpoints for optional resources
#####

# Create Private Endpoints for storage account that will hold test data. Create all endpoints for the hell of it. Likely only need blob and file.
#
module "private_endpoint_st_data_blob" {
  depends_on = [
    module.private_endpoint_container_registry
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_data.name
  resource_id      = module.storage_account_data.id
  subresource_name = "blob"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.blob.core.windows.net"
  ]
}

module "private_endpoint_st_data_file" {
  depends_on = [
    module.private_endpoint_st_data_blob
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_data.name
  resource_id      = module.storage_account_data.id
  subresource_name = "file"


  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.file.core.windows.net"
  ]
}

module "private_endpoint_st_data_table" {
  depends_on = [
    module.private_endpoint_st_data_file
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_data.name
  resource_id      = module.storage_account_data.id
  subresource_name = "table"


  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.table.core.windows.net"
  ]
}

module "private_endpoint_st_data_queue" {
  depends_on = [
    module.private_endpoint_st_data_table
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_data.name
  resource_id      = module.storage_account_data.id
  subresource_name = "queue"


  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.queue.core.windows.net"
  ]
}

module "private_endpoint_st_data_dfs" {
  depends_on = [
    module.private_endpoint_st_data_queue
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.workload_vnet_location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.storage_account_data.name
  resource_id      = module.storage_account_data.id
  subresource_name = "dfs"


  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.dfs.core.windows.net"
  ]
}

# Create a Private Endpoint for the AI Search instance
#
module "private_endpoint_ai_search" {
  depends_on = [
    module.private_endpoint_st_data_dfs
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.ai_search.name
  resource_id      = module.ai_search.id
  subresource_name = "searchService"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.search.windows.net"
  ]
}

# Create a Private Endpoint for the Azure OpenAI Service instance
#
module "private_endpoint_openai" {
  depends_on = [
    module.private_endpoint_ai_search
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.openai_aifoundry.name
  resource_id      = module.openai_aifoundry.id
  subresource_name = "account"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.openai.azure.com"
  ]
}

# Create a Private Endpoint for the AI Service instance
#
module "private_endpoint_ai_service" {
  depends_on = [
    module.private_endpoint_openai
  ]

  source              = "../../modules/private-endpoint"
  random_string       = var.random_string
  location            = var.workload_vnet_location
  location_code       = var.location_code
  resource_group_name = azurerm_resource_group.rgwork.name
  tags                = var.tags

  resource_name    = module.ai_services_aifoundry.name
  resource_id      = module.ai_services_aifoundry.id
  subresource_name = "account"

  subnet_id = var.subnet_id
  private_dns_zone_ids = [
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.openai.azure.com",
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.cognitiveservices.azure.com",
    "/subscriptions/${var.sub_id}/resourceGroups/${var.resource_group_name_dns}/providers/Microsoft.Network/privateDnsZones/privatelink.services.ai.azure.com"
  ]
}

## Create non-human role assignments
##

# Create role assignments granting Azure OpenAI Service and AI Service system-managed identities Search Data Index Reader and Search Service Contributor 
# role on the AI Search instance to support the chat with your data feature in the Chat Playground
resource "azurerm_role_assignment" "aisearch_index_reader_openai_mi" {
  depends_on = [
    module.openai_aifoundry
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.openai_aifoundry.managed_identity_principal_id}${module.ai_search.name}indexreader")
  scope                = module.ai_search.id
  role_definition_name = "Search Index Data Reader"
  principal_id         = module.openai_aifoundry.managed_identity_principal_id
}

resource "azurerm_role_assignment" "aisearch_reader_openai_mi" {
  depends_on = [
    module.openai_aifoundry
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.openai_aifoundry.managed_identity_principal_id}${module.ai_search.name}searchcontr")
  scope                = module.ai_search.id
  role_definition_name = "Search Service Contributor"
  principal_id         = module.openai_aifoundry.managed_identity_principal_id
}

resource "azurerm_role_assignment" "aisearch_index_reader_ai_services_mi" {
  depends_on = [
    module.ai_services_aifoundry
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.ai_services_aifoundry.managed_identity_principal_id}${module.ai_search.name}indexreader")
  scope                = module.ai_search.id
  role_definition_name = "Search Index Data Reader"
  principal_id         = module.ai_services_aifoundry.managed_identity_principal_id
}

resource "azurerm_role_assignment" "aisearch_reader_ai_services_mi" {
  depends_on = [
    module.ai_services_aifoundry
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.ai_services_aifoundry.managed_identity_principal_id}${module.ai_search.name}searchcontr")
  scope                = module.ai_search.id
  role_definition_name = "Search Service Contributor"
  principal_id         = module.ai_services_aifoundry.managed_identity_principal_id
}

# Create role assignment granting the AI Search instance Congitive Services OpenAI User to the Azure OpenAI Service instance and AI Services instance
# so it can create embeddings if using an AI Search index skill to pull data into the index
resource "azurerm_role_assignment" "openai_cognitive_services_openai_contributor_ai_search" {
  depends_on = [
    module.ai_search
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.ai_search.managed_identity_principal_id}${module.openai_aifoundry.name}cont")
  scope                = module.openai_aifoundry.id
  role_definition_name = "Cognitive Services OpenAI User"
  principal_id         = module.ai_search.managed_identity_principal_id
}

resource "azurerm_role_assignment" "ai_services_cognitive_services_openai_contributor_ai_search" {
  depends_on = [
    module.ai_search
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.ai_search.managed_identity_principal_id}${module.ai_services_aifoundry.name}cont")
  scope                = module.ai_services_aifoundry.id
  role_definition_name = "Cognitive Services OpenAI User"
  principal_id         = module.ai_search.managed_identity_principal_id
}

# Create role assignment granting the AI Foundry Project system-managed identity the Reader role over the resource group containing the private endpoints
# for the default storage account and data storage account. This is required for if you want to upload your data to the storage accounts
# when using the chat with your data feature and building the index within the AI Foundry
resource "azurerm_role_assignment" "rg_reader_project" {
  depends_on = [
    time_sleep.wait_project_identities
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${azapi_resource.foundry_project.output.identity.principalId}rg")
  scope                = azurerm_resource_group.rgwork.id
  role_definition_name = "Reader"
  principal_id         = azapi_resource.foundry_project.output.identity.principalId
}

# Create role assignment granting the AI Search instance the Blob Data Reader role over the data storage account to allow it to 
# read data from the storage account when building the index using AI Search SkillSets
resource "azurerm_role_assignment" "aisearch_blob_data_reader_data_sa" {
  depends_on = [
    module.private_endpoint_st_data_blob
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${module.ai_search.managed_identity_principal_id}${module.storage_account_data.name}blob")
  scope                = module.storage_account_data.id
  role_definition_name = "Storage Blob Data Reader"
  principal_id         = module.ai_search.managed_identity_principal_id
}

## Create human role assignments
##

# Create role assignments for the data scientist granting them the Storage Blob Data Contributor and Storage File Data Privileged Contributor role
# over the default storage account. This is required to allow the user to use create and modify Prompt Flows.
resource "azurerm_role_assignment" "blob_perm_aifoundry_sa_user" {
  depends_on = [
    module.private_endpoint_foundry_hub
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.storage_account_ai_foundry.name}blob")
  scope                = module.storage_account_ai_foundry.id
  role_definition_name = "Storage Blob Data Contributor"
  principal_id         = var.user_object_id
}

resource "azurerm_role_assignment" "file_perm_aifoundry_sa_user" {
  depends_on = [
    azurerm_role_assignment.blob_perm_aifoundry_sa_user
  ]

  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.storage_account_ai_foundry.name}file")
  scope                = module.storage_account_ai_foundry.id
  role_definition_name = "Storage File Data Privileged Contributor"
  principal_id         = var.user_object_id
}

# Create role assignments for the data scientist granting them the Storage Blob Data Contributor and Storage File Data Privileged Contributor role
# over the data storage account. This is required to allow the users to upload data to the storage account.
resource "azurerm_role_assignment" "blob_perm_data_sa_user" {
  depends_on = [
    azurerm_role_assignment.file_perm_aifoundry_sa_user
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.storage_account_data.name}blob")
  scope                = module.storage_account_data.id
  role_definition_name = "Storage Blob Data Contributor"
  principal_id         = var.user_object_id
}

resource "azurerm_role_assignment" "file_perm_data_sa_user" {
  depends_on = [
    azurerm_role_assignment.blob_perm_data_sa_user
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.storage_account_data.name}file")
  scope                = module.storage_account_data.id
  role_definition_name = "Storage File Data Privileged Contributor"
  principal_id         = var.user_object_id
}

# Create the role assignment for the data scientist to grant them the AI Developer role the AI Foundry Hub instance and AI Foundry Project instance.
# This assumes the AI Developer will manage both the hub and project. If not, then this role only needs to be granted on the AI Foundry Project instance.
resource "azurerm_role_assignment" "ai_foundry_hub_admin" {
  depends_on = [
    azapi_resource.foundry_project
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${azapi_resource.foundry_hub.name}aidev")
  scope                = azapi_resource.foundry_hub.id
  role_definition_name = "Azure AI Developer"
  principal_id         = var.user_object_id
}

resource "azurerm_role_assignment" "ai_foundry_project_admin" {
  depends_on = [
    time_sleep.wait_project_identities
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${azapi_resource.foundry_project.name}aidev")
  scope                = azapi_resource.foundry_project.id
  role_definition_name = "Azure AI Developer"
  principal_id         = var.user_object_id
}

# Create the role assignment for the data scientist to grant them the Cognitive Services OpenAI Contributor role over the Azure OpenAI Service instance.
# This is required to allow the user to send Chat Completions, create embeddings, fine-tune models, or upload data for the on your own data use case.
# If you only want the user to be able to create ChatCompletions and Embeddings, then you can use the Cognitive Services OpenAI User role instead.

resource "azurerm_role_assignment" "openai_user_contributor" {
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.openai_aifoundry.name}cont")
  scope                = module.openai_aifoundry.id
  role_definition_name = "Cognitive Services OpenAI Contributor"
  principal_id         = var.user_object_id
}

resource "azurerm_role_assignment" "ai_service_openai_user_contributor" {
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.ai_services_aifoundry.name}cont")
  scope                = module.ai_services_aifoundry.id
  role_definition_name = "Cognitive Services OpenAI Contributor"
  principal_id         = var.user_object_id
}

# Create the role assignment for the data scientist to grant them the Search Service Contributor to create new indexes from the Chat Playground. 
# When using this feature, the service uses a delegated identity flow to create the indexes, so the user needs
# the Search Service Contributor role to allow them to create indexes.
resource "azurerm_role_assignment" "aisearch_user_service_contributor" {
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.ai_search.name}servicecont")
  scope                = module.ai_search.id
  role_definition_name = "Search Service Contributor"
  principal_id         = var.user_object_id
}

# Create the role assignment for the data scientist to grant them the Search Index Data Contributor to create new records in existing indexes from the Chat Playground. 
# When using this feature, the service uses a delegated identity flow to create the indexes, so the user needs
# the Search Service Contributor role to allow them to create indexes.
resource "azurerm_role_assignment" "aisearch_user_data_contributor" {
  depends_on = [
    azurerm_role_assignment.aisearch_user_service_contributor
  ]
  name                 = uuidv5("dns", "${azurerm_resource_group.rgwork.name}${var.user_object_id}${module.ai_search.name}datacont")
  scope                = module.ai_search.id
  role_definition_name = "Search Index Data Contributor"
  principal_id         = var.user_object_id
}

